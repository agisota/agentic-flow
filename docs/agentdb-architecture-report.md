# AgentDB CLI and MCP Tools Architecture Report

## Executive Summary

This report provides a comprehensive analysis of the AgentDB CLI command structure, MCP tools implementation, and their integration with the ReasoningBank memory system. It identifies key extension points for integrating DSPy features and provides recommendations for API design.

**Date:** 2025-11-16
**Version:** 1.0
**Author:** Backend API Developer Agent

---

## Table of Contents

1. [Architecture Overview](#architecture-overview)
2. [CLI Command Structure](#cli-command-structure)
3. [MCP Tools Implementation](#mcp-tools-implementation)
4. [Command-to-Reasoning-Bank Flow](#command-to-reasoning-bank-flow)
5. [DSPy Integration Points](#dspy-integration-points)
6. [API Design Recommendations](#api-design-recommendations)
7. [Implementation Roadmap](#implementation-roadmap)

---

## 1. Architecture Overview

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Agentic-Flow Entry Points                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ CLI Proxy (bin/agentic-flow)                                  â”‚
â”‚  â€¢ AgentDB CLI (bin/agentdb)                                     â”‚
â”‚  â€¢ MCP Server (fastmcp/stdio)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Command Layer                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ CLI Argument Parser (utils/cli.ts)                           â”‚
â”‚  â€¢ Command Routers:                                              â”‚
â”‚    - reasoningbankCommands.ts                                    â”‚
â”‚    - mcpCommands.ts                                              â”‚
â”‚    - agentdb-cli.ts                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Service Layer                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ReasoningBank:                      AgentDB Controllers:        â”‚
â”‚  â€¢ HybridReasoningBank              â€¢ ReflexionMemory           â”‚
â”‚  â€¢ AdvancedMemorySystem             â€¢ SkillLibrary              â”‚
â”‚  â€¢ Core Functions:                   â€¢ CausalMemoryGraph        â”‚
â”‚    - retrieve.ts                     â€¢ CausalRecall             â”‚
â”‚    - judge.ts                        â€¢ NightlyLearner           â”‚
â”‚    - distill.ts                      â€¢ ExplainableRecall        â”‚
â”‚    - consolidate.ts                  â€¢ EmbeddingService         â”‚
â”‚    - matts.ts                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Data Layer                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ SQLite Databases:                                             â”‚
â”‚    - agentdb.db (frontier features)                             â”‚
â”‚    - memory.db (reasoningbank)                                  â”‚
â”‚  â€¢ Schemas:                                                      â”‚
â”‚    - frontier-schema.sql (causal graphs, certificates)          â”‚
â”‚    - schema.sql (standard agentdb)                              â”‚
â”‚    - reasoningbank migrations                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

#### 1. CLI Entry Points
- **Main CLI**: `/agentic-flow/src/cli-proxy.ts` - Routes to different command modes
- **AgentDB CLI**: `/agentic-flow/src/agentdb/cli/agentdb-cli.ts` - Dedicated AgentDB commands
- **Argument Parser**: `/agentic-flow/src/utils/cli.ts` - Unified CLI options parsing

#### 2. MCP Tools
- **FastMCP Server**: `/agentic-flow/src/mcp/fastmcp/servers/claude-flow-sdk.ts`
- **Tool Definitions**: `/agentic-flow/src/mcp/fastmcp/tools/`
  - `agent/` - Agent execution, spawning, management
  - `swarm/` - Swarm initialization and orchestration

#### 3. Memory Systems
- **ReasoningBank**: Learning memory system (Google DeepMind paper)
- **AgentDB**: State-of-the-art agent memory patterns
- **Hybrid Backend**: Combines both systems for optimal performance

---

## 2. CLI Command Structure

### 2.1 Main CLI Modes

The CLI supports multiple operation modes defined in `/agentic-flow/src/utils/cli.ts`:

```typescript
interface CliOptions {
  mode: 'agent' | 'parallel' | 'list' | 'mcp' | 'mcp-manager' |
        'config' | 'agent-manager' | 'proxy' | 'quic' |
        'claude-code' | 'reasoningbank' | 'federation';
  // ... other options
}
```

### 2.2 ReasoningBank Commands

**Location**: `/agentic-flow/src/utils/reasoningbankCommands.ts`

```bash
npx agentic-flow reasoningbank <command>
```

| Command | Description | Implementation |
|---------|-------------|----------------|
| `demo` | Interactive demo showing 0% â†’ 100% learning | `demo-comparison.ts` |
| `test` | Run validation test suite | `test-validation.ts` |
| `init` | Initialize database schema | `db/queries.ts` |
| `benchmark` | Run performance benchmarks | `benchmark.ts` |
| `status` | Show memory statistics | SQL queries on patterns table |
| `consolidate` | Run memory consolidation | `core/consolidate.ts` |
| `list` | List memories with filters | SQL queries with sorting |

**Key Features**:
- Spawns external scripts using `child_process.spawn()`
- Direct database access for status/list commands
- Async/await pattern with error handling
- Formatted console output with colors

### 2.3 AgentDB CLI Commands

**Location**: `/agentic-flow/src/agentdb/cli/agentdb-cli.ts`

```bash
agentdb <command> <subcommand> [options]
```

#### Command Groups:

**1. Causal Commands** (`causal`)
```bash
agentdb causal add-edge <cause> <effect> <uplift> [confidence] [sample-size]
agentdb causal experiment create <name> <cause> <effect>
agentdb causal experiment add-observation <id> <is-treatment> <outcome>
agentdb causal experiment calculate <id>
agentdb causal query [cause] [effect] [min-confidence] [min-uplift]
```

**2. Recall Commands** (`recall`)
```bash
agentdb recall with-certificate <query> [k] [alpha] [beta] [gamma]
```

**3. Learner Commands** (`learner`)
```bash
agentdb learner run [min-attempts] [min-success-rate] [min-confidence]
agentdb learner prune [min-confidence] [min-uplift] [max-age-days]
```

**4. Reflexion Commands** (`reflexion`)
```bash
agentdb reflexion store <session-id> <task> <reward> <success> [critique]
agentdb reflexion retrieve <task> [k] [min-reward] [only-failures]
agentdb reflexion critique-summary <task>
agentdb reflexion prune [max-age-days] [max-reward]
```

**5. Skill Commands** (`skill`)
```bash
agentdb skill create <name> <description> [code]
agentdb skill search <query> [k]
agentdb skill consolidate [min-attempts] [min-reward] [time-window-days]
agentdb skill prune [min-uses] [min-success-rate] [max-age-days]
```

**6. Database Commands** (`db`)
```bash
agentdb db stats
```

### 2.4 CLI Architecture Pattern

```typescript
class AgentDBCLI {
  private db?: Database.Database;
  private causalGraph?: CausalMemoryGraph;
  private causalRecall?: CausalRecall;
  private explainableRecall?: ExplainableRecall;
  private nightlyLearner?: NightlyLearner;
  private reflexion?: ReflexionMemory;
  private skills?: SkillLibrary;
  private embedder?: EmbeddingService;

  async initialize(dbPath: string): Promise<void> {
    // 1. Initialize database
    // 2. Load schema
    // 3. Initialize embedding service
    // 4. Initialize controllers
  }

  // Command handler methods
  async causalAddEdge(params: {...}): Promise<void> { }
  async reflexionStoreEpisode(params: {...}): Promise<void> { }
  // ... etc
}
```

**Design Patterns**:
- **Lazy Initialization**: Controllers initialized once on startup
- **Dependency Injection**: Database and embedder passed to controllers
- **Command Pattern**: Each command is a method with typed parameters
- **Error Handling**: Try-catch with formatted error messages
- **Colored Output**: Terminal colors for success/error/info messages

---

## 3. MCP Tools Implementation

### 3.1 MCP Server Architecture

**Location**: `/agentic-flow/src/mcp/fastmcp/servers/claude-flow-sdk.ts`

The MCP server uses **FastMCP** (v3.19.0) for Model Context Protocol implementation:

```typescript
const server = new FastMCP({
  name: 'claude-flow-sdk',
  version: '1.0.0'
});

// Tool registration pattern
server.addTool({
  name: 'tool_name',
  description: 'Tool description',
  parameters: z.object({ /* zod schema */ }),
  execute: async (params) => { /* implementation */ }
});

server.start({ transportType: 'stdio' });
```

### 3.2 Available MCP Tools

**Current Tools** (6 total):

| Tool | Description | Parameters | Implementation |
|------|-------------|------------|----------------|
| `memory_store` | Store value in persistent memory | key, value, namespace, ttl | Calls `npx claude-flow@alpha memory store` |
| `memory_retrieve` | Retrieve value from memory | key, namespace | Calls `npx claude-flow@alpha memory retrieve` |
| `memory_search` | Search keys matching pattern | pattern, namespace, limit | Calls `npx claude-flow@alpha memory search` |
| `swarm_init` | Initialize multi-agent swarm | topology, maxAgents, strategy | Calls `npx claude-flow@alpha swarm init` |
| `agent_spawn` | Spawn new agent in swarm | type, capabilities, name | Calls `npx claude-flow@alpha agent spawn` |
| `task_orchestrate` | Orchestrate task across swarm | task, strategy, priority, maxAgents | Calls `npx claude-flow@alpha task orchestrate` |

### 3.3 MCP Tool Pattern

All tools follow this pattern:

```typescript
server.addTool({
  name: 'tool_name',
  description: 'Clear description for LLM',
  parameters: z.object({
    param: z.string().min(1).describe('Parameter description'),
    optional: z.number().optional().default(10).describe('Optional param')
  }),
  execute: async ({ param, optional }) => {
    try {
      // 1. Build CLI command
      const cmd = `npx claude-flow@alpha command "${param}" --option ${optional}`;

      // 2. Execute with execSync
      const result = execSync(cmd, {
        encoding: 'utf-8',
        maxBuffer: 10 * 1024 * 1024
      });

      // 3. Return structured JSON response
      return JSON.stringify({
        success: true,
        data: result.trim(),
        timestamp: new Date().toISOString()
      }, null, 2);
    } catch (error: any) {
      // 4. Throw descriptive error
      throw new Error(`Failed to execute: ${error.message}`);
    }
  }
});
```

### 3.4 MCP Tool Categories

**Agent Tools** (`/mcp/fastmcp/tools/agent/`):
- `execute.ts` - Execute agent with task
- `add-agent.ts` - Add custom agent
- `add-command.ts` - Add custom command
- `list.ts` - List available agents
- `parallel.ts` - Parallel agent execution

**Swarm Tools** (`/mcp/fastmcp/tools/swarm/`):
- `init.ts` - Initialize swarm topology
- `spawn.ts` - Spawn agents
- `orchestrate.ts` - Task orchestration

### 3.5 Tool Execution Flow

```
1. Claude Code calls MCP tool via SDK
   â†“
2. FastMCP server receives tool call
   â†“
3. Zod validates parameters
   â†“
4. Execute function runs
   â†“
5. Builds CLI command string
   â†“
6. Executes via child_process.execSync()
   â†“
7. Captures stdout/stderr
   â†“
8. Returns formatted JSON response
   â†“
9. Claude Code receives result
```

---

## 4. Command-to-Reasoning-Bank Flow

### 4.1 ReasoningBank Integration Points

The ReasoningBank system integrates at multiple levels:

#### Level 1: Direct CLI Commands
```bash
# User executes ReasoningBank command
npx agentic-flow reasoningbank demo

# Flow:
1. CLI router detects 'reasoningbank' mode
2. handleReasoningBankCommand() called
3. Spawns demo-comparison.ts script
4. Script uses ReasoningBank API directly
```

#### Level 2: Agent Task Execution
```typescript
// Agent executes task with memory
const result = await runTask({
  taskId: 'task-123',
  agentId: 'coder',
  query: 'Implement authentication',
  executeFn: async (memories) => {
    // Agent uses retrieved memories
    // Executes task
    return trajectory;
  }
});

// Flow:
1. retrieveMemories() - Query similar past experiences
2. executeFn() - Agent performs task with context
3. judgeTrajectory() - Evaluate success/failure
4. distillMemories() - Extract learnings
5. consolidate() - Merge and prune memories
```

#### Level 3: MCP Tool Integration
```typescript
// Claude Code uses MCP tool
await mcp.memory_store({
  key: 'task-result',
  value: JSON.stringify(result),
  namespace: 'agent-coder'
});

// Flow:
1. MCP tool receives call
2. Executes: npx claude-flow@alpha memory store
3. Claude Flow CLI stores in ReasoningBank
4. Memory available for future retrievals
```

### 4.2 Data Flow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Input                                 â”‚
â”‚  CLI Command / MCP Tool Call / Agent Task                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Command Router                                  â”‚
â”‚  â€¢ Parse arguments                                                â”‚
â”‚  â€¢ Validate parameters                                            â”‚
â”‚  â€¢ Route to appropriate handler                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ReasoningBank / AgentDB                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ 1. RETRIEVE Phase                                           â”‚â”‚
â”‚  â”‚    â€¢ Compute query embedding                                â”‚â”‚
â”‚  â”‚    â€¢ k-NN search in pattern_embeddings                      â”‚â”‚
â”‚  â”‚    â€¢ MMR selection for diversity                            â”‚â”‚
â”‚  â”‚    â€¢ Filter by domain/agent/confidence                      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ 2. EXECUTE Phase                                            â”‚â”‚
â”‚  â”‚    â€¢ Inject memories into context                           â”‚â”‚
â”‚  â”‚    â€¢ Run agent/controller logic                             â”‚â”‚
â”‚  â”‚    â€¢ Track trajectory steps                                 â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ 3. JUDGE Phase                                              â”‚â”‚
â”‚  â”‚    â€¢ Evaluate trajectory success                            â”‚â”‚
â”‚  â”‚    â€¢ Compute reward/confidence                              â”‚â”‚
â”‚  â”‚    â€¢ Classify verdict (success/failure/partial)             â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ 4. DISTILL Phase                                            â”‚â”‚
â”‚  â”‚    â€¢ Extract key insights                                   â”‚â”‚
â”‚  â”‚    â€¢ Compute embeddings                                     â”‚â”‚
â”‚  â”‚    â€¢ Store as new patterns                                  â”‚â”‚
â”‚  â”‚    â€¢ Link causally if applicable                            â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ 5. CONSOLIDATE Phase (periodic)                             â”‚â”‚
â”‚  â”‚    â€¢ Detect duplicates                                      â”‚â”‚
â”‚  â”‚    â€¢ Find contradictions                                    â”‚â”‚
â”‚  â”‚    â€¢ Prune low-quality memories                             â”‚â”‚
â”‚  â”‚    â€¢ Update skill library                                   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Database Persistence                            â”‚
â”‚  â€¢ patterns (reasoning memories)                                 â”‚
â”‚  â€¢ pattern_embeddings (vector search)                            â”‚
â”‚  â€¢ pattern_links (causal edges)                                  â”‚
â”‚  â€¢ task_trajectories (execution traces)                          â”‚
â”‚  â€¢ causal_edges (intervention effects)                           â”‚
â”‚  â€¢ episodes (reflexion memory)                                   â”‚
â”‚  â€¢ skills (reusable capabilities)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.3 Key Database Tables

**ReasoningBank Tables**:
```sql
-- Core pattern storage
patterns (
  id, type, pattern_data, confidence, usage_count,
  success_count, created_at, updated_at
)

-- Vector embeddings for similarity search
pattern_embeddings (
  pattern_id, embedding_blob, model_version
)

-- Causal relationships
pattern_links (
  from_pattern_id, to_pattern_id, link_type, strength
)

-- Execution traces
task_trajectories (
  id, task_id, agent_id, steps_json, verdict, created_at
)
```

**AgentDB Frontier Tables**:
```sql
-- Causal intervention effects
causal_edges (
  from_memory_id, to_memory_id, uplift, confidence,
  sample_size, evidence_ids
)

-- A/B experiment tracking
causal_experiments (
  id, name, hypothesis, treatment_id, control_id,
  uplift, p_value, confidence_interval_low/high
)

-- Explainable recall certificates
recall_certificates (
  id, query_id, chunk_ids, minimal_why,
  redundancy_ratio, merkle_root, proof_chain
)

-- Reflexion episodes
episodes (
  id, session_id, task, input, output, critique,
  reward, success, latency_ms, tokens_used
)

-- Skill library
skills (
  id, name, description, signature, code,
  success_rate, uses, avg_reward
)
```

---

## 5. DSPy Integration Points

### 5.1 What is DSPy?

DSPy is a framework for programming with language models using composable modules and automatic optimization. Key features:
- **Declarative Signatures**: Define input/output schemas
- **Module Composition**: Chain multiple LM operations
- **Automatic Optimization**: Tune prompts and few-shot examples
- **Teleprompters**: Optimize module chains end-to-end

### 5.2 Identified Integration Points

#### Integration Point 1: Query Optimization Module

**Location**: Between CLI and ReasoningBank retrieval

```typescript
// Current: Direct query to embeddings
const memories = await retrieveMemories(query);

// With DSPy: Optimize query reformulation
class QueryOptimizer extends dspy.Module {
  signature = "query -> optimized_query, search_strategy"

  forward(query: string) {
    // DSPy optimizes this to generate better queries
    return {
      optimizedQuery: "...",
      searchStrategy: "hybrid|semantic|causal"
    }
  }
}
```

**Benefits**:
- Automatic query expansion
- Context-aware reformulation
- Few-shot optimization from past successes

#### Integration Point 2: Trajectory Evaluation

**Location**: AgentDB `judge.ts` function

```typescript
// Current: Rule-based or LLM-based judgment
const verdict = await judgeTrajectory(trajectory, query);

// With DSPy: Optimized evaluation chain
class TrajectoryJudge extends dspy.Module {
  signature = "trajectory, expected_outcome -> verdict, confidence, reasoning"

  forward(trajectory, expected) {
    // DSPy optimizes prompts for accurate evaluation
    return { verdict, confidence, reasoning }
  }
}
```

**Benefits**:
- Consistent evaluation criteria
- Calibrated confidence scores
- Explainable judgments

#### Integration Point 3: Memory Distillation

**Location**: AgentDB `distill.ts` function

```typescript
// Current: Extract insights from trajectory
const insights = await distillMemories(trajectory, verdict, query);

// With DSPy: Multi-step reasoning chain
class MemoryDistiller extends dspy.ChainOfThought {
  signature = "trajectory, verdict -> insights[], importance_scores[]"

  forward(trajectory, verdict) {
    // DSPy chains: extract â†’ rank â†’ format
    return { insights, importanceScores }
  }
}
```

**Benefits**:
- Higher quality abstractions
- Ranked insights by importance
- Reduced redundancy

#### Integration Point 4: Causal Discovery

**Location**: AgentDB `NightlyLearner.ts`

```typescript
// Current: Statistical analysis of patterns
const edges = await nightlyLearner.discover();

// With DSPy: Hybrid causal reasoning
class CausalDiscoverer extends dspy.Module {
  signature = "pattern_set -> causal_hypotheses[]"

  forward(patterns) {
    // Combines statistical + LLM reasoning
    return causalHypotheses
  }
}
```

**Benefits**:
- Discover non-obvious causality
- Generate testable hypotheses
- Reduce false positives

#### Integration Point 5: Skill Synthesis

**Location**: AgentDB `SkillLibrary.ts`

```typescript
// Current: Template-based skill creation
const skills = skillLibrary.consolidateEpisodesIntoSkills();

// With DSPy: Program synthesis from examples
class SkillSynthesizer extends dspy.Module {
  signature = "episodes[] -> skill_code, skill_signature, tests[]"

  forward(episodes) {
    // Generate reusable skills from successful episodes
    return { code, signature, tests }
  }
}
```

**Benefits**:
- Automatic skill extraction
- Generate test cases
- Optimize skill code

### 5.3 DSPy Module Architecture

```typescript
// File: /agentic-flow/src/agentdb/dspy/index.ts
import * as dspy from 'dspy-ai';

export class AgentDBDSPy {
  private lm: dspy.LanguageModel;
  private queryOptimizer: QueryOptimizer;
  private trajectoryJudge: TrajectoryJudge;
  private memoryDistiller: MemoryDistiller;
  private causalDiscoverer: CausalDiscoverer;
  private skillSynthesizer: SkillSynthesizer;

  constructor(config: DSPyConfig) {
    this.lm = new dspy.OpenAI({ model: config.model });
    dspy.settings.configure({ lm: this.lm });

    // Initialize modules
    this.queryOptimizer = new QueryOptimizer();
    this.trajectoryJudge = new TrajectoryJudge();
    // ... etc
  }

  async optimizeQuery(query: string): Promise<OptimizedQuery> {
    return await this.queryOptimizer.forward(query);
  }

  async judgeTrajectory(trajectory: Trajectory): Promise<Verdict> {
    return await this.trajectoryJudge.forward(trajectory);
  }

  // Compile/optimize modules with few-shot examples
  async compile(trainset: Example[]) {
    const teleprompter = new dspy.teleprompt.BootstrapFewShot();
    this.queryOptimizer = await teleprompter.compile(
      this.queryOptimizer,
      trainset
    );
  }
}
```

### 5.4 CLI Integration

```bash
# New commands for DSPy features
agentdb dspy optimize-query <query>
agentdb dspy judge-trajectory <trajectory-id>
agentdb dspy distill-memory <trajectory-id>
agentdb dspy discover-causality [options]
agentdb dspy synthesize-skill <episode-ids...>

# Training and compilation
agentdb dspy compile --module query-optimizer --trainset ./data/queries.json
agentdb dspy compile --module trajectory-judge --trainset ./data/judgments.json

# Status and inspection
agentdb dspy status
agentdb dspy inspect <module-name>
```

### 5.5 MCP Tool Integration

```typescript
// New MCP tools
server.addTool({
  name: 'dspy_optimize_query',
  description: 'Optimize a query using DSPy for better retrieval',
  parameters: z.object({
    query: z.string(),
    context: z.string().optional()
  }),
  execute: async ({ query, context }) => {
    const optimized = await agentdb.dspy.optimizeQuery(query, context);
    return JSON.stringify(optimized, null, 2);
  }
});

server.addTool({
  name: 'dspy_judge_trajectory',
  description: 'Judge trajectory quality using optimized DSPy evaluator',
  parameters: z.object({
    trajectoryId: z.number(),
    criteria: z.array(z.string()).optional()
  }),
  execute: async ({ trajectoryId, criteria }) => {
    const verdict = await agentdb.dspy.judgeTrajectory(trajectoryId, criteria);
    return JSON.stringify(verdict, null, 2);
  }
});
```

---

## 6. API Design Recommendations

### 6.1 Directory Structure

```
/agentic-flow/src/agentdb/
â”œâ”€â”€ cli/
â”‚   â”œâ”€â”€ agentdb-cli.ts          # Main CLI (existing)
â”‚   â””â”€â”€ dspy-commands.ts        # NEW: DSPy command handlers
â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ CausalMemoryGraph.ts    # Existing
â”‚   â”œâ”€â”€ ReflexionMemory.ts      # Existing
â”‚   â””â”€â”€ DSPyController.ts       # NEW: DSPy module orchestration
â”œâ”€â”€ dspy/
â”‚   â”œâ”€â”€ index.ts                # NEW: Main DSPy exports
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ QueryOptimizer.ts   # NEW: Query optimization module
â”‚   â”‚   â”œâ”€â”€ TrajectoryJudge.ts  # NEW: Evaluation module
â”‚   â”‚   â”œâ”€â”€ MemoryDistiller.ts  # NEW: Distillation module
â”‚   â”‚   â”œâ”€â”€ CausalDiscoverer.ts # NEW: Causal discovery module
â”‚   â”‚   â””â”€â”€ SkillSynthesizer.ts # NEW: Skill synthesis module
â”‚   â”œâ”€â”€ teleprompters/
â”‚   â”‚   â”œâ”€â”€ BootstrapOptimizer.ts  # NEW: Few-shot optimization
â”‚   â”‚   â””â”€â”€ MetricOptimizer.ts     # NEW: Metric-driven optimization
â”‚   â””â”€â”€ types.ts                # NEW: TypeScript definitions
â”œâ”€â”€ mcp/
â”‚   â””â”€â”€ dspy-tools.ts           # NEW: MCP tool definitions
â””â”€â”€ schemas/
    â””â”€â”€ dspy-schema.sql         # NEW: DSPy metadata tables
```

### 6.2 Core Interfaces

```typescript
// File: /agentic-flow/src/agentdb/dspy/types.ts

export interface DSPyConfig {
  model: string;              // 'claude-3-5-sonnet-20241022'
  temperature: number;
  maxTokens: number;
  provider: 'anthropic' | 'openrouter';
  cacheDir?: string;         // Cache compiled modules
}

export interface DSPyModule {
  name: string;
  signature: string;         // DSPy signature format
  forward(...args: any[]): Promise<any>;
  compile(trainset: Example[]): Promise<void>;
}

export interface OptimizedQuery {
  original: string;
  optimized: string;
  strategy: 'semantic' | 'hybrid' | 'causal';
  expansions: string[];
  confidence: number;
}

export interface Verdict {
  label: 'success' | 'failure' | 'partial';
  confidence: number;
  reasoning: string;
  criteria: {
    name: string;
    score: number;
    justification: string;
  }[];
}

export interface DistilledInsight {
  text: string;
  importance: number;       // 0-1 score
  category: 'pattern' | 'constraint' | 'heuristic';
  applicability: string[];  // Domains where this applies
}

export interface CausalHypothesis {
  cause: string;
  effect: string;
  mechanism: string;
  confidence: number;
  evidenceCount: number;
  suggestedExperiment: string;
}

export interface SynthesizedSkill {
  name: string;
  description: string;
  signature: {
    inputs: Record<string, string>;
    outputs: Record<string, string>;
  };
  code: string;
  tests: string[];
  derivedFrom: number[];    // Episode IDs
}
```

### 6.3 Controller API

```typescript
// File: /agentic-flow/src/agentdb/controllers/DSPyController.ts

import Database from 'better-sqlite3';
import { EmbeddingService } from './EmbeddingService.js';
import * as dspy from 'dspy-ai';

export class DSPyController {
  constructor(
    private db: Database.Database,
    private embedder: EmbeddingService,
    private config: DSPyConfig
  ) {
    // Initialize DSPy language model
    const lm = new dspy.OpenAI({
      model: config.model,
      apiKey: config.apiKey || process.env.ANTHROPIC_API_KEY
    });
    dspy.settings.configure({ lm });
  }

  /**
   * Optimize query for better retrieval
   */
  async optimizeQuery(query: string, context?: string): Promise<OptimizedQuery> {
    const optimizer = await this.getOrCompileModule('query_optimizer');
    const result = await optimizer.forward({ query, context });

    // Store optimization result for training
    this.db.prepare(`
      INSERT INTO dspy_optimizations (query, optimized, strategy, created_at)
      VALUES (?, ?, ?, ?)
    `).run(query, result.optimized, result.strategy, Date.now());

    return result;
  }

  /**
   * Judge trajectory with structured evaluation
   */
  async judgeTrajectory(
    trajectoryId: number,
    criteria?: string[]
  ): Promise<Verdict> {
    // Load trajectory from database
    const trajectory = this.loadTrajectory(trajectoryId);

    // Use DSPy judge module
    const judge = await this.getOrCompileModule('trajectory_judge');
    const verdict = await judge.forward({
      trajectory: trajectory.steps,
      expectedOutcome: trajectory.goal,
      criteria: criteria || ['correctness', 'efficiency', 'safety']
    });

    // Store verdict
    this.db.prepare(`
      UPDATE task_trajectories
      SET verdict = ?, verdict_confidence = ?, reasoning = ?
      WHERE id = ?
    `).run(verdict.label, verdict.confidence, verdict.reasoning, trajectoryId);

    return verdict;
  }

  /**
   * Distill insights from trajectory
   */
  async distillMemory(trajectoryId: number): Promise<DistilledInsight[]> {
    const trajectory = this.loadTrajectory(trajectoryId);
    const verdict = await this.judgeTrajectory(trajectoryId);

    const distiller = await this.getOrCompileModule('memory_distiller');
    const insights = await distiller.forward({
      trajectory: trajectory.steps,
      verdict: verdict.label,
      success: verdict.label === 'success'
    });

    // Store insights as patterns
    for (const insight of insights) {
      const embedding = await this.embedder.embed(insight.text);

      this.db.prepare(`
        INSERT INTO patterns (
          type, pattern_data, confidence, created_at
        ) VALUES (?, ?, ?, ?)
      `).run(
        'reasoning_memory',
        JSON.stringify({
          title: insight.text.substring(0, 100),
          description: insight.text,
          category: insight.category,
          importance: insight.importance
        }),
        verdict.confidence,
        Date.now()
      );
    }

    return insights;
  }

  /**
   * Discover causal relationships from patterns
   */
  async discoverCausality(options: {
    minConfidence?: number;
    maxHypotheses?: number;
  }): Promise<CausalHypothesis[]> {
    // Load recent patterns
    const patterns = this.db.prepare(`
      SELECT * FROM patterns
      WHERE type = 'reasoning_memory'
      ORDER BY created_at DESC
      LIMIT 100
    `).all();

    const discoverer = await this.getOrCompileModule('causal_discoverer');
    const hypotheses = await discoverer.forward({
      patterns,
      minConfidence: options.minConfidence || 0.6
    });

    // Store hypotheses for experimentation
    for (const hyp of hypotheses.slice(0, options.maxHypotheses || 10)) {
      this.db.prepare(`
        INSERT INTO causal_hypotheses (
          cause, effect, mechanism, confidence, suggested_experiment, created_at
        ) VALUES (?, ?, ?, ?, ?, ?)
      `).run(
        hyp.cause,
        hyp.effect,
        hyp.mechanism,
        hyp.confidence,
        hyp.suggestedExperiment,
        Date.now()
      );
    }

    return hypotheses;
  }

  /**
   * Synthesize reusable skill from episodes
   */
  async synthesizeSkill(episodeIds: number[]): Promise<SynthesizedSkill> {
    // Load episodes
    const episodes = episodeIds.map(id =>
      this.db.prepare('SELECT * FROM episodes WHERE id = ?').get(id)
    );

    const synthesizer = await this.getOrCompileModule('skill_synthesizer');
    const skill = await synthesizer.forward({
      episodes,
      successThreshold: 0.8
    });

    // Store skill
    const skillId = this.db.prepare(`
      INSERT INTO skills (
        name, description, signature, code, created_at
      ) VALUES (?, ?, ?, ?, ?)
    `).run(
      skill.name,
      skill.description,
      JSON.stringify(skill.signature),
      skill.code,
      Date.now()
    ).lastInsertRowid;

    return { ...skill, id: skillId };
  }

  /**
   * Compile DSPy module with few-shot examples
   */
  async compileModule(
    moduleName: string,
    trainset: Example[],
    metric?: (pred: any, gold: any) => number
  ): Promise<void> {
    const module = this.modules[moduleName];
    if (!module) {
      throw new Error(`Unknown module: ${moduleName}`);
    }

    // Use BootstrapFewShot teleprompter
    const teleprompter = new dspy.teleprompt.BootstrapFewShot(metric);
    const compiledModule = await teleprompter.compile(module, trainset);

    // Save compiled module
    this.modules[moduleName] = compiledModule;

    // Store compilation metadata
    this.db.prepare(`
      INSERT INTO dspy_compilations (
        module_name, trainset_size, metric_name, compiled_at
      ) VALUES (?, ?, ?, ?)
    `).run(moduleName, trainset.length, metric?.name || 'default', Date.now());
  }

  private async getOrCompileModule(name: string): Promise<DSPyModule> {
    // Check if module is compiled and cached
    // Load from cache or compile fresh
    // Return module
  }

  private loadTrajectory(id: number) {
    // Load trajectory from database
  }
}
```

### 6.4 CLI Command Handlers

```typescript
// File: /agentic-flow/src/agentdb/cli/dspy-commands.ts

export async function handleDSPyCommands(
  cli: AgentDBCLI,
  subcommand: string,
  args: string[]
): Promise<void> {
  const dspy = cli.dspy; // DSPyController instance

  switch (subcommand) {
    case 'optimize-query': {
      const query = args[0];
      const context = args[1];

      log.header('\nğŸ¯ Optimizing Query with DSPy');
      log.info(`Original: "${query}"`);

      const result = await dspy.optimizeQuery(query, context);

      console.log('\n' + 'â•'.repeat(80));
      console.log(`${colors.bright}Optimized Query:${colors.reset}`);
      console.log(`  ${result.optimized}`);
      console.log(`\n${colors.bright}Strategy:${colors.reset} ${result.strategy}`);
      console.log(`${colors.bright}Confidence:${colors.reset} ${result.confidence.toFixed(2)}`);

      if (result.expansions.length > 0) {
        console.log(`\n${colors.bright}Expansions:${colors.reset}`);
        result.expansions.forEach((exp, i) => {
          console.log(`  ${i + 1}. ${exp}`);
        });
      }
      console.log('â•'.repeat(80));
      break;
    }

    case 'judge-trajectory': {
      const trajectoryId = parseInt(args[0]);
      const criteria = args.slice(1);

      log.header('\nâš–ï¸  Judging Trajectory with DSPy');
      log.info(`Trajectory ID: ${trajectoryId}`);

      const verdict = await dspy.judgeTrajectory(trajectoryId, criteria);

      console.log('\n' + 'â•'.repeat(80));
      console.log(`${colors.bright}Verdict:${colors.reset} ${verdict.label}`);
      console.log(`${colors.bright}Confidence:${colors.reset} ${verdict.confidence.toFixed(2)}`);
      console.log(`\n${colors.bright}Reasoning:${colors.reset}`);
      console.log(`  ${verdict.reasoning}`);

      console.log(`\n${colors.bright}Criteria Scores:${colors.reset}`);
      verdict.criteria.forEach(c => {
        console.log(`  â€¢ ${c.name}: ${c.score.toFixed(2)}`);
        console.log(`    ${c.justification}`);
      });
      console.log('â•'.repeat(80));
      break;
    }

    case 'distill-memory': {
      const trajectoryId = parseInt(args[0]);

      log.header('\nğŸ’­ Distilling Memory with DSPy');

      const insights = await dspy.distillMemory(trajectoryId);

      console.log('\n' + 'â•'.repeat(80));
      console.log(`${colors.bright}Distilled ${insights.length} Insights:${colors.reset}\n`);

      insights.forEach((insight, i) => {
        console.log(`${colors.bright}${i + 1}. ${insight.category.toUpperCase()}${colors.reset}`);
        console.log(`   Importance: ${insight.importance.toFixed(2)}`);
        console.log(`   ${insight.text}`);
        console.log(`   Applies to: ${insight.applicability.join(', ')}`);
        console.log('');
      });
      console.log('â•'.repeat(80));

      log.success(`Stored ${insights.length} insights in memory`);
      break;
    }

    case 'discover-causality': {
      const minConfidence = args[0] ? parseFloat(args[0]) : 0.6;
      const maxHypotheses = args[1] ? parseInt(args[1]) : 10;

      log.header('\nğŸ”¬ Discovering Causal Relationships');
      log.info(`Min Confidence: ${minConfidence}`);

      const hypotheses = await dspy.discoverCausality({
        minConfidence,
        maxHypotheses
      });

      console.log('\n' + 'â•'.repeat(80));
      console.log(`${colors.bright}Discovered ${hypotheses.length} Causal Hypotheses:${colors.reset}\n`);

      hypotheses.forEach((hyp, i) => {
        console.log(`${colors.bright}${i + 1}. ${hyp.cause} â†’ ${hyp.effect}${colors.reset}`);
        console.log(`   Confidence: ${hyp.confidence.toFixed(2)}`);
        console.log(`   Mechanism: ${hyp.mechanism}`);
        console.log(`   Evidence: ${hyp.evidenceCount} observations`);
        console.log(`   Suggested Experiment: ${hyp.suggestedExperiment}`);
        console.log('');
      });
      console.log('â•'.repeat(80));
      break;
    }

    case 'synthesize-skill': {
      const episodeIds = args.map(id => parseInt(id));

      log.header('\nğŸ¨ Synthesizing Skill from Episodes');
      log.info(`Episodes: ${episodeIds.join(', ')}`);

      const skill = await dspy.synthesizeSkill(episodeIds);

      console.log('\n' + 'â•'.repeat(80));
      console.log(`${colors.bright}Synthesized Skill: ${skill.name}${colors.reset}`);
      console.log(`\n${colors.bright}Description:${colors.reset}`);
      console.log(`  ${skill.description}`);
      console.log(`\n${colors.bright}Signature:${colors.reset}`);
      console.log(`  Inputs: ${Object.keys(skill.signature.inputs).join(', ')}`);
      console.log(`  Outputs: ${Object.keys(skill.signature.outputs).join(', ')}`);
      console.log(`\n${colors.bright}Generated Code:${colors.reset}`);
      console.log(skill.code);
      console.log(`\n${colors.bright}Generated Tests:${colors.reset}`);
      skill.tests.forEach((test, i) => {
        console.log(`  ${i + 1}. ${test}`);
      });
      console.log('â•'.repeat(80));

      log.success(`Skill stored with ID: ${skill.id}`);
      break;
    }

    case 'compile': {
      const moduleName = args[args.indexOf('--module') + 1];
      const trainsetPath = args[args.indexOf('--trainset') + 1];

      log.header('\nğŸ”§ Compiling DSPy Module');
      log.info(`Module: ${moduleName}`);
      log.info(`Trainset: ${trainsetPath}`);

      // Load trainset
      const trainset = JSON.parse(fs.readFileSync(trainsetPath, 'utf-8'));

      await dspy.compileModule(moduleName, trainset);

      log.success(`Module ${moduleName} compiled successfully`);
      log.info('Module cached for future use');
      break;
    }

    case 'status': {
      log.header('\nğŸ“Š DSPy Module Status');

      const stats = await dspy.getStats();

      console.log('\n' + 'â•'.repeat(80));
      console.log(`${colors.bright}Available Modules:${colors.reset}`);
      Object.entries(stats.modules).forEach(([name, info]) => {
        console.log(`  â€¢ ${name}`);
        console.log(`    Compiled: ${info.compiled ? 'Yes' : 'No'}`);
        console.log(`    Last used: ${info.lastUsed || 'Never'}`);
        console.log(`    Usage count: ${info.usageCount}`);
      });

      console.log(`\n${colors.bright}Optimization History:${colors.reset}`);
      console.log(`  Query optimizations: ${stats.queryOptimizations}`);
      console.log(`  Trajectory judgments: ${stats.trajectoryJudgments}`);
      console.log(`  Memory distillations: ${stats.memoryDistillations}`);
      console.log(`  Causal discoveries: ${stats.causalDiscoveries}`);
      console.log(`  Skill syntheses: ${stats.skillSyntheses}`);
      console.log('â•'.repeat(80));
      break;
    }

    default:
      log.error(`Unknown DSPy subcommand: ${subcommand}`);
      printDSPyHelp();
  }
}

function printDSPyHelp() {
  console.log(`
${colors.bright}${colors.cyan}DSPy Integration - Optimized Language Model Programming${colors.reset}

${colors.bright}USAGE:${colors.reset}
  agentdb dspy <subcommand> [options]

${colors.bright}SUBCOMMANDS:${colors.reset}
  optimize-query <query> [context]
    Optimize a query for better retrieval using DSPy

  judge-trajectory <trajectory-id> [criteria...]
    Judge trajectory quality with structured evaluation

  distill-memory <trajectory-id>
    Distill insights from trajectory into memory patterns

  discover-causality [min-confidence] [max-hypotheses]
    Discover causal relationships from memory patterns

  synthesize-skill <episode-id>...
    Synthesize reusable skill from successful episodes

  compile --module <name> --trainset <path>
    Compile DSPy module with few-shot examples

  status
    Show DSPy module status and usage statistics

${colors.bright}EXAMPLES:${colors.reset}
  # Optimize query
  agentdb dspy optimize-query "implement authentication"

  # Judge trajectory
  agentdb dspy judge-trajectory 123 correctness efficiency safety

  # Distill memory
  agentdb dspy distill-memory 456

  # Discover causality
  agentdb dspy discover-causality 0.7 10

  # Synthesize skill
  agentdb dspy synthesize-skill 101 102 103

  # Compile module
  agentdb dspy compile --module query_optimizer --trainset ./data/queries.json

  # Show status
  agentdb dspy status
  `);
}
```

### 6.5 Database Schema Extensions

```sql
-- File: /agentic-flow/src/agentdb/schemas/dspy-schema.sql

-- DSPy module compilations
CREATE TABLE IF NOT EXISTS dspy_compilations (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  module_name TEXT NOT NULL,
  trainset_size INTEGER NOT NULL,
  metric_name TEXT,
  metric_score REAL,
  compiled_at INTEGER NOT NULL,
  cache_path TEXT,
  metadata JSON
);

CREATE INDEX idx_dspy_compilations_module ON dspy_compilations(module_name);
CREATE INDEX idx_dspy_compilations_compiled ON dspy_compilations(compiled_at DESC);

-- DSPy query optimizations
CREATE TABLE IF NOT EXISTS dspy_optimizations (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  query TEXT NOT NULL,
  optimized TEXT NOT NULL,
  strategy TEXT NOT NULL,
  confidence REAL,
  created_at INTEGER NOT NULL,
  retrieval_improvement REAL, -- Measured improvement
  metadata JSON
);

CREATE INDEX idx_dspy_optimizations_query ON dspy_optimizations(query);
CREATE INDEX idx_dspy_optimizations_created ON dspy_optimizations(created_at DESC);

-- DSPy causal hypotheses
CREATE TABLE IF NOT EXISTS causal_hypotheses (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  cause TEXT NOT NULL,
  effect TEXT NOT NULL,
  mechanism TEXT,
  confidence REAL NOT NULL,
  evidence_count INTEGER DEFAULT 0,
  suggested_experiment TEXT,
  validated BOOLEAN DEFAULT 0,
  validation_result TEXT,
  created_at INTEGER NOT NULL,
  validated_at INTEGER,
  metadata JSON
);

CREATE INDEX idx_causal_hypotheses_confidence ON causal_hypotheses(confidence DESC);
CREATE INDEX idx_causal_hypotheses_validated ON causal_hypotheses(validated);

-- DSPy module usage tracking
CREATE TABLE IF NOT EXISTS dspy_usage (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  module_name TEXT NOT NULL,
  input_tokens INTEGER,
  output_tokens INTEGER,
  latency_ms INTEGER,
  success BOOLEAN,
  error_message TEXT,
  timestamp INTEGER NOT NULL
);

CREATE INDEX idx_dspy_usage_module ON dspy_usage(module_name);
CREATE INDEX idx_dspy_usage_timestamp ON dspy_usage(timestamp DESC);

-- DSPy few-shot examples
CREATE TABLE IF NOT EXISTS dspy_examples (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  module_name TEXT NOT NULL,
  input_data TEXT NOT NULL,
  output_data TEXT NOT NULL,
  quality_score REAL,
  source TEXT, -- 'manual', 'auto-generated', 'validated'
  created_at INTEGER NOT NULL,
  metadata JSON
);

CREATE INDEX idx_dspy_examples_module ON dspy_examples(module_name);
CREATE INDEX idx_dspy_examples_quality ON dspy_examples(quality_score DESC);
```

---

## 7. Implementation Roadmap

### Phase 1: Foundation (Week 1-2)

**Objectives**:
- Set up DSPy integration infrastructure
- Create base module classes
- Implement database schema extensions

**Tasks**:
1. Install DSPy dependencies
   ```bash
   npm install dspy-ai zod
   ```

2. Create directory structure
   ```bash
   mkdir -p src/agentdb/dspy/{modules,teleprompters,cli}
   ```

3. Implement core types (`dspy/types.ts`)
4. Create DSPyController (`controllers/DSPyController.ts`)
5. Add database schemas (`schemas/dspy-schema.sql`)
6. Run migrations

**Deliverables**:
- [ ] DSPy types defined
- [ ] DSPyController implemented
- [ ] Database schemas created
- [ ] Unit tests for core functionality

### Phase 2: Query Optimization (Week 3)

**Objectives**:
- Implement QueryOptimizer module
- Integrate with retrieval pipeline
- Add CLI commands

**Tasks**:
1. Implement `QueryOptimizer` DSPy module
2. Add query optimization to `retrieve.ts`
3. Implement CLI command: `agentdb dspy optimize-query`
4. Create MCP tool: `dspy_optimize_query`
5. Collect training examples
6. Implement compilation with few-shot

**Deliverables**:
- [ ] QueryOptimizer module working
- [ ] CLI command functional
- [ ] MCP tool integrated
- [ ] Benchmark showing improvement

### Phase 3: Trajectory Evaluation (Week 4)

**Objectives**:
- Implement TrajectoryJudge module
- Replace/augment existing judgment logic
- Add structured evaluation

**Tasks**:
1. Implement `TrajectoryJudge` DSPy module
2. Integrate with `judge.ts`
3. Implement CLI command: `agentdb dspy judge-trajectory`
4. Create MCP tool: `dspy_judge_trajectory`
5. Define evaluation criteria
6. Compile with validated examples

**Deliverables**:
- [ ] TrajectoryJudge module working
- [ ] Integration with existing code
- [ ] CLI command functional
- [ ] Improved judgment accuracy

### Phase 4: Memory Distillation (Week 5)

**Objectives**:
- Implement MemoryDistiller module
- Enhance insight extraction
- Improve memory quality

**Tasks**:
1. Implement `MemoryDistiller` DSPy module
2. Integrate with `distill.ts`
3. Implement CLI command: `agentdb dspy distill-memory`
4. Create importance scoring
5. Add deduplication logic

**Deliverables**:
- [ ] MemoryDistiller module working
- [ ] Higher quality abstractions
- [ ] CLI command functional
- [ ] Reduced redundancy metrics

### Phase 5: Causal Discovery (Week 6)

**Objectives**:
- Implement CausalDiscoverer module
- Augment NightlyLearner
- Generate testable hypotheses

**Tasks**:
1. Implement `CausalDiscoverer` DSPy module
2. Integrate with `NightlyLearner.ts`
3. Implement CLI command: `agentdb dspy discover-causality`
4. Create hypothesis validation framework
5. Add experiment suggestion logic

**Deliverables**:
- [ ] CausalDiscoverer module working
- [ ] Hypothesis generation functional
- [ ] CLI command functional
- [ ] Validation framework

### Phase 6: Skill Synthesis (Week 7)

**Objectives**:
- Implement SkillSynthesizer module
- Automate skill extraction
- Generate test cases

**Tasks**:
1. Implement `SkillSynthesizer` DSPy module
2. Integrate with `SkillLibrary.ts`
3. Implement CLI command: `agentdb dspy synthesize-skill`
4. Add code generation logic
5. Implement test generation

**Deliverables**:
- [ ] SkillSynthesizer module working
- [ ] Automated skill extraction
- [ ] CLI command functional
- [ ] Generated skills validated

### Phase 7: Module Compilation & Optimization (Week 8)

**Objectives**:
- Implement compilation pipeline
- Create teleprompters
- Set up continuous optimization

**Tasks**:
1. Implement compilation CLI: `agentdb dspy compile`
2. Create BootstrapOptimizer teleprompter
3. Create MetricOptimizer teleprompter
4. Set up training data collection
5. Implement automatic retraining

**Deliverables**:
- [ ] Compilation pipeline working
- [ ] Teleprompters implemented
- [ ] Training data collected
- [ ] Continuous optimization setup

### Phase 8: MCP Tools & Integration (Week 9)

**Objectives**:
- Create all MCP tools
- Document integration patterns
- Add examples

**Tasks**:
1. Implement all DSPy MCP tools
2. Add to MCP server registration
3. Create integration examples
4. Write API documentation
5. Create video tutorials

**Deliverables**:
- [ ] All MCP tools working
- [ ] Integration documented
- [ ] Examples provided
- [ ] Documentation complete

### Phase 9: Testing & Benchmarking (Week 10)

**Objectives**:
- Comprehensive testing
- Performance benchmarks
- Quality metrics

**Tasks**:
1. Write unit tests for all modules
2. Write integration tests
3. Create benchmark suite
4. Measure improvements
5. Optimize hot paths

**Deliverables**:
- [ ] 100% test coverage
- [ ] Benchmark results
- [ ] Performance report
- [ ] Quality metrics

### Phase 10: Documentation & Release (Week 11-12)

**Objectives**:
- Complete documentation
- Create tutorials
- Prepare release

**Tasks**:
1. Write API documentation
2. Create user guides
3. Make video tutorials
4. Write blog post
5. Prepare release notes
6. Publish to npm

**Deliverables**:
- [ ] API documentation complete
- [ ] User guides published
- [ ] Tutorials available
- [ ] Package released

---

## 8. Success Metrics

### Performance Metrics

1. **Query Optimization**
   - Target: 20% improvement in retrieval relevance
   - Measure: Top-k accuracy on test queries

2. **Trajectory Judgment**
   - Target: 15% improvement in verdict accuracy
   - Measure: Agreement with human evaluators

3. **Memory Distillation**
   - Target: 30% reduction in memory redundancy
   - Measure: Duplicate detection and quality scores

4. **Causal Discovery**
   - Target: 10+ validated causal hypotheses per month
   - Measure: Experiment validation success rate

5. **Skill Synthesis**
   - Target: 5+ reusable skills extracted per week
   - Measure: Skill reuse rate and success rate

### Quality Metrics

1. **Code Quality**
   - 90%+ test coverage
   - No critical security vulnerabilities
   - TypeScript strict mode compliance

2. **API Quality**
   - Consistent error handling
   - Comprehensive logging
   - Clear documentation

3. **User Experience**
   - Intuitive CLI commands
   - Helpful error messages
   - Fast response times (<100ms for CLI)

---

## 9. Risk Mitigation

### Technical Risks

1. **DSPy Integration Complexity**
   - **Risk**: DSPy API changes or compatibility issues
   - **Mitigation**: Pin DSPy version, maintain adapter layer

2. **Performance Degradation**
   - **Risk**: DSPy modules slow down operations
   - **Mitigation**: Implement caching, async processing, timeouts

3. **Quality Regression**
   - **Risk**: DSPy modules produce lower quality results
   - **Mitigation**: A/B testing, fallback to existing logic, monitoring

### Operational Risks

1. **Increased Costs**
   - **Risk**: More LLM calls increase API costs
   - **Mitigation**: Caching, batching, cost limits, ONNX fallback

2. **Complexity**
   - **Risk**: System becomes harder to maintain
   - **Mitigation**: Clear documentation, modular design, examples

3. **User Adoption**
   - **Risk**: Users don't adopt new features
   - **Mitigation**: Gradual rollout, tutorials, support

---

## 10. Conclusion

This report provides a comprehensive analysis of the AgentDB CLI and MCP tools architecture, identifying clear integration points for DSPy features. The recommended implementation follows a phased approach that minimizes risk while delivering incremental value.

### Key Takeaways

1. **Solid Foundation**: Existing architecture is well-structured for extension
2. **Clear Integration Points**: Five key areas identified for DSPy enhancement
3. **Backward Compatibility**: New features augment rather than replace existing functionality
4. **Incremental Value**: Each phase delivers measurable improvements
5. **Risk Mitigation**: Comprehensive strategies for technical and operational risks

### Next Steps

1. **Review and approve** this architecture document
2. **Set up development environment** with DSPy dependencies
3. **Begin Phase 1** (Foundation) implementation
4. **Establish metrics** tracking and monitoring
5. **Schedule regular reviews** to assess progress

---

## Appendix A: File Locations Reference

### Existing Files
- Main CLI: `/agentic-flow/src/cli-proxy.ts`
- CLI Parser: `/agentic-flow/src/utils/cli.ts`
- AgentDB CLI: `/agentic-flow/src/agentdb/cli/agentdb-cli.ts`
- ReasoningBank Commands: `/agentic-flow/src/utils/reasoningbankCommands.ts`
- MCP Server: `/agentic-flow/src/mcp/fastmcp/servers/claude-flow-sdk.ts`
- AgentDB Controllers: `/agentic-flow/src/agentdb/controllers/`
- Database Schemas: `/agentic-flow/src/agentdb/schemas/`

### New Files (To Be Created)
- DSPy Types: `/agentic-flow/src/agentdb/dspy/types.ts`
- DSPy Controller: `/agentic-flow/src/agentdb/controllers/DSPyController.ts`
- DSPy Commands: `/agentic-flow/src/agentdb/cli/dspy-commands.ts`
- DSPy Modules: `/agentic-flow/src/agentdb/dspy/modules/*.ts`
- DSPy MCP Tools: `/agentic-flow/src/agentdb/mcp/dspy-tools.ts`
- DSPy Schema: `/agentic-flow/src/agentdb/schemas/dspy-schema.sql`

## Appendix B: Dependencies

### Required Dependencies
```json
{
  "dependencies": {
    "dspy-ai": "^0.2.0",
    "zod": "^3.25.76",
    "better-sqlite3": "^11.10.0",
    "@xenova/transformers": "^2.17.2"
  }
}
```

### Peer Dependencies
```json
{
  "peerDependencies": {
    "@anthropic-ai/sdk": "^0.65.0"
  }
}
```

---

**End of Report**
